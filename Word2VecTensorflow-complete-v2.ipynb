{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "024b6ff9",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 9\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnltk\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcorpus\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m stopwords\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m----> 9\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mre\u001b[39;00m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnltk\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "from itertools import chain\n",
    "import logging\n",
    "import gzip\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import re\n",
    "import nltk\n",
    "import sys\n",
    "from collections import OrderedDict\n",
    "from sklearn.manifold import TSNE # used to reduce demonsionality of word embeddings to shape 1, 2 for graphing\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "    \n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format=\"%(asctime)s : %(levelname)s : %(message)s\",\n",
    "    handlers=[\n",
    "        logging.FileHandler(\"Z:/ProjectCourse/complete.log\"),\n",
    "        logging.StreamHandler(sys.stdout)\n",
    "    ]\n",
    ")\n",
    "\n",
    "stop_words = set(stopwords.words('english')) | {\" \", \"\"}\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae00ebd9",
   "metadata": {},
   "source": [
    "## Import Text and Process it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2ea57cca",
   "metadata": {},
   "outputs": [],
   "source": [
    "digit_regex = re.compile(rb\"^[1-9][0-9]*\\t\")\n",
    "def read_input(input_file):\n",
    "    \"\"\"This method reads the input file which is in gzip format\"\"\"\n",
    "    input_size = 0\n",
    "    logging.info(\"reading file {0}...this may take a while\".format(input_file))\n",
    "    with gzip.open(input_file, 'rb') as f:\n",
    "        for i, line in enumerate(f):\n",
    "\n",
    "            if (input_size == 3300000):\n",
    "                logging.info(\"Reached desired inpute size of 3300000\")\n",
    "                break\n",
    "\n",
    "            if (i % 100000 == 0):\n",
    "                logging.info(\"read {0} abstracts\".format(i))\n",
    "            \n",
    "\n",
    "            if len(re.sub(digit_regex, rb\"\", line)) == 1:\n",
    "                continue\n",
    "            \n",
    "            input_size += 1\n",
    "            # do some pre-processing and return list of words for each review\n",
    "            # text\n",
    "            yield gensim.utils.simple_preprocess(line)\n",
    "\n",
    "num_regex = re.compile(r\"^[1-9][0-9]*\\t\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70c73eb8",
   "metadata": {},
   "source": [
    "# Create a dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d275a057",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-11-23 20:49:27,018 : INFO : reading file Z:/ProjectCourse/Corpus/id_abstract.gz...this may take a while\n",
      "2022-11-23 20:49:35,914 : INFO : read 200000 abstracts\n",
      "2022-11-23 20:49:39,194 : INFO : read 300000 abstracts\n",
      "2022-11-23 20:49:42,222 : INFO : read 400000 abstracts\n",
      "2022-11-23 20:50:01,023 : INFO : Reached desired inpute size of 400000\n"
     ]
    }
   ],
   "source": [
    "input_file = \"Z:/ProjectCourse/Corpus/id_abstract.gz\"\n",
    "sentences  = list(chain(*read_input(input_file, 400000)))#3300000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08a4ccf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the vocabulary\n",
    "words = set()\n",
    "for sentence in sentences:\n",
    "    words = words.union(set(sentence))\n",
    "    \n",
    "word2int = {}\n",
    "int2word = {}\n",
    "vocab_size = len(words) # gives the total number of unique words\n",
    "for i,word in enumerate(words):\n",
    "    word2int[word] = i\n",
    "    int2word[i] = word\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82405846",
   "metadata": {},
   "source": [
    "# Generate training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "63bf736c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['he', 'is'], ['he', 'the'], ['is', 'he'], ['is', 'the'], ['is', 'king'], ['the', 'he'], ['the', 'is'], ['the', 'king'], ['king', 'is'], ['king', 'the'], ['the', 'king'], ['the', 'is'], ['king', 'the'], ['king', 'is'], ['king', 'royal'], ['is', 'the'], ['is', 'king'], ['is', 'royal'], ['royal', 'king'], ['royal', 'is'], ['she', 'is'], ['she', 'the'], ['is', 'she'], ['is', 'the'], ['is', 'royal'], ['the', 'she'], ['the', 'is'], ['the', 'royal'], ['the', 'queen'], ['royal', 'is'], ['royal', 'the'], ['royal', 'queen'], ['queen', 'the'], ['queen', 'royal']]\n"
     ]
    }
   ],
   "source": [
    "# Creates a of word pairs with a window size of 10\n",
    "# Where up to 10 words before and 10 words after the occurce of the center word\n",
    "# from our corpus\n",
    "data = []\n",
    "WINDOW_SIZE = 10\n",
    "for sentence in sentences:\n",
    "    for word_index, word in enumerate(sentence):\n",
    "        for nb_word in sentence[max(word_index - WINDOW_SIZE, 0) : min(word_index + WINDOW_SIZE, len(sentence)) + 1] : \n",
    "            if nb_word != word:\n",
    "                data.append([word, nb_word])\n",
    "                \n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "739a09c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_training_data = []\n",
    "output_training_data = []\n",
    "temp = []\n",
    "window_size = 10\n",
    "for i in range(len(words)):\n",
    "    f = i - window_size\n",
    "    end = i + window_size\n",
    "    selected_word = words[i]\n",
    "    for j in range(start, i):\n",
    "        if j >= 0:\n",
    "            temp.append((selected_word, words[j]))\n",
    "    for j in range(i + 1, end):\n",
    "        if j < len(vocab):\n",
    "            temp.append((selected_word, words[j]))\n",
    "\n",
    "# creating one hot encodings \n",
    "for pair in temp_dict:\n",
    "    temp_input = np.zeros(len(vocab))\n",
    "    temp_output = np.zeros(len(vocab))\n",
    "    \n",
    "    temp_input[char_to_int[pair[0]]] = 1\n",
    "    temp_output[char_to_int[pair[1]]] = 1\n",
    "    \n",
    "    input_training_data .append(temp_input)\n",
    "    output_training_data.append(temp_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "745be699",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epochs, input_training_data, output_training_data, batch_size, optimizer, x, y):\n",
    "    \n",
    "    nbatches = int(len(input_training_data)/batch_size)\n",
    "    \n",
    "    init = tf.global_variables_initializer()\n",
    "    gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction = 0.40)\n",
    "    sess = tf.Session(config = tf.ConfigProto(gpu_options = gpu_options))\n",
    "    sess.run(init)\n",
    "    saver = tf.train.Saver()\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        cost = 0\n",
    "        for i in range(nbatches-1):\n",
    "            batch_x = input_training_data[i * batch_size :(i + 1) * batch_size]\n",
    "            batch_y = output_training_data[i * batch_size :(i + 1) * batch_size]\n",
    "            _, j = sess.run([optimizer, cost], feed_dict = {x:batch_x, y:batch_y})\n",
    "            cost += j / nbatches\n",
    "        logging.info(f\"Current epoch: {epoch}, Cost: {cost}\")\n",
    "    return saver.save(sess,'./saved_complete_v2_models/complete.weights')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0701233a",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_size = 300\n",
    "learning_rate = 0.025\n",
    "\n",
    "x = tf.placeholder(tf.float32,shape = (None,len(vocab)))\n",
    "y = tf.placeholder(tf.float32,shape = (None,len(vocab)))\n",
    "\n",
    "weight1 = tf.Variable(tf.random_normal([len(vocab), embedding_size]),dtype = tf.float32)\n",
    "bias1 = tf.Variable(tf.random_normal([embedding_size]), dtype = tf.float32)\n",
    "weight2 = tf.Variable(tf.random_normal([embedding_size, len(vocab)]), dtype = tf.float32)\n",
    "bias2 = tf.Variable(tf.random_normal([len(vocab)]), dtype = tf.float32)\n",
    "\n",
    "hidden_y = tf.matmul(tf.matmul(x,weight11) + bias1,weight2) + bias2\n",
    "\n",
    "cost = tf.reduce_mean(tf.losses.mean_squared_error(hidden_y,y))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate).minimize(cost)\n",
    "\n",
    "batch_size = 10000\n",
    "epochs = 10\n",
    "train(epochs, input_training_data, output_training_data, batch_size, optimizer, x, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "838a84cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d6843e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "embeddings = dict()\n",
    "for i in vocab:\n",
    "    temp_a = np.zeros([1,len(vocab)])\n",
    "    temp_a[0][char_to_int[i]] = 1\n",
    "    temp_emb = sess.run([_y],feed_dict = {x:temp_a})\n",
    "    temp_emb = np.array(temp_emb)\n",
    "    #print(temp_emb.shape)\n",
    "    embeddings[i] = temp_emb.reshape([len(vocab)])\n",
    "    #print(embeddings[i].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8ca9f60",
   "metadata": {},
   "source": [
    "## Looking at the hidden representations Weight1 and bias1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "01a6c0a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-2.4667048  -1.0390921   0.5201295  -0.42721358  0.33458644]\n",
      " [-0.11102659  0.20847504  1.623999   -0.01977071  3.474004  ]\n",
      " [ 0.627525   -0.4716701   1.4797018   0.13992879 -0.8566276 ]\n",
      " [ 0.6442408  -0.42976695 -0.5576406   0.9899494   1.5625219 ]\n",
      " [ 0.5571808  -0.13938767 -1.3208493  -2.4646916  -0.6998081 ]\n",
      " [ 0.8087424  -0.55020505  1.6411406   0.12971856 -0.68120277]\n",
      " [ 0.6365183  -0.01430083 -1.9740577   0.99436265 -1.2716385 ]]\n",
      "--------------------------\n",
      "[ 1.0741833  -0.1815876   0.65087634  0.10639327 -1.0893831 ]\n",
      "--------------------------\n"
     ]
    }
   ],
   "source": [
    "print(sess.run(weight1))\n",
    "print('--------------------------')\n",
    "print(sess.run(bias1))\n",
    "print('--------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "40f4fc10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.3925215  -1.2206796   1.1710058  -0.3208203  -0.7547967 ]\n",
      " [ 0.96315676  0.02688743  2.2748754   0.08662256  2.384621  ]\n",
      " [ 1.7017083  -0.6532577   2.130578    0.24632207 -1.9460107 ]\n",
      " [ 1.7184241  -0.6113546   0.09323573  1.0963427   0.4731388 ]\n",
      " [ 1.6313641  -0.32097527 -0.66997296 -2.3582983  -1.7891912 ]\n",
      " [ 1.8829257  -0.7317927   2.292017    0.23611182 -1.7705859 ]\n",
      " [ 1.7107017  -0.19588844 -1.3231814   1.1007559  -2.3610215 ]]\n"
     ]
    }
   ],
   "source": [
    "vectors = sess.run(weight1 + bias1)\n",
    "print(vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "ee0e6e59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.7184241  -0.6113546   0.09323573  1.0963427   0.4731388 ]\n"
     ]
    }
   ],
   "source": [
    "# Getting the representation of a word, i.e., queen\n",
    "print(vectors[word2int['queen']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "350e805f",
   "metadata": {},
   "source": [
    "## Dirty imlpementation for finding the closest vector to a given word using euclidean distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "95411c89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# should the vectors be normalized before finding closest neighbour\n",
    "def euclidean_dist(vec1, vec2):\n",
    "    return np.sqrt(np.sum((vec1-vec2)**2))\n",
    "\n",
    "def find_closest(word_index, vectors):\n",
    "    min_dist = 10000 # to act like positive infinity\n",
    "    min_index = -1    \n",
    "    query_vector = vectors[word_index]    \n",
    "    for index, vector in enumerate(vectors):\n",
    "        if euclidean_dist(vector, query_vector) < min_dist and not np.array_equal(vector, query_vector):\n",
    "            min_dist = euclidean_dist(vector, query_vector)\n",
    "            min_index = index\n",
    "            return min_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "00ac2010",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "king --> royal\n",
      "queen --> royal\n",
      "royal --> king\n"
     ]
    }
   ],
   "source": [
    "print('king', '-->', int2word[find_closest(word2int['king'], vectors)])\n",
    "print('queen', '-->', int2word[find_closest(word2int['queen'], vectors)])\n",
    "print('royal', '-->', int2word[find_closest(word2int['royal'], vectors)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08687686",
   "metadata": {},
   "source": [
    "## Plotting the vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "7af31a9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TSNE(n_components=2, random_state=0)\n",
    "np.set_printoptions(suppress=True)\n",
    "vectors = model.fit_transform(vectors) \n",
    "\n",
    "normalizer = preprocessing.Normalizer()\n",
    "vectors =  normalizer.fit_transform(vectors, 'l2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "02528c1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'royal', 'king', 'she', 'queen', 'the', 'he', 'is'}\n",
      "royal 0.89717036\n",
      "king 0.25030422\n",
      "she 0.96019673\n",
      "queen 0.5068005\n",
      "the -0.9047838\n",
      "he 0.9838481\n",
      "is -0.4028841\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "print(words)\n",
    "for word in words:\n",
    "    print(word, vectors[word2int[word]][1])\n",
    "    ax.annotate(word, (vectors[word2int[word]][0],vectors[word2int[word]][1] ))\n",
    "    ax.set_xlim(min([vectors[word2int[w]][0] for w in words])-1, max([vectors[word2int[w]][0] for w in words])+1)\n",
    "    ax.set_ylim(min([vectors[word2int[w]][1] for w in words])-1, max([vectors[word2int[w]][1] for w in words])+1)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
